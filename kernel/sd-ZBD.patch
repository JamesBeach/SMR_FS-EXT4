diff --git a/drivers/scsi/Kconfig b/drivers/scsi/Kconfig
index b021bcb..ec4faa4 100644
--- a/drivers/scsi/Kconfig
+++ b/drivers/scsi/Kconfig
@@ -200,6 +200,15 @@ config SCSI_ENCLOSURE
 	  it has an enclosure device.  Selecting this option will just allow
 	  certain enclosure conditions to be reported and is not required.
 
+config SCSI_ZBC
+	bool "SCSI ZBC (zoned block commands) Support"
+	depends on SCSI && BLK_DEV_ZONED
+	default y
+	help
+	  Enable support for ZBC (zoned block commands) devices.
+
+	  If unsure say Y.
+
 config SCSI_CONSTANTS
 	bool "Verbose SCSI error reporting (kernel size +=75K)"
 	depends on SCSI
diff --git a/drivers/scsi/Makefile b/drivers/scsi/Makefile
index dee160a..43239b1 100644
--- a/drivers/scsi/Makefile
+++ b/drivers/scsi/Makefile
@@ -174,6 +174,7 @@ hv_storvsc-y			:= storvsc_drv.o
 
 sd_mod-objs	:= sd.o
 sd_mod-$(CONFIG_BLK_DEV_INTEGRITY) += sd_dif.o
+sd_mod-$(CONFIG_SCSI_ZBC) += sd_zbc.o
 
 sr_mod-objs	:= sr.o sr_ioctl.o sr_vendor.o
 ncr53c8xx-flags-$(CONFIG_SCSI_ZALON) \
diff --git a/drivers/scsi/sd.c b/drivers/scsi/sd.c
old mode 100644
new mode 100755
index 6b78476..2147c7c
--- a/drivers/scsi/sd.c
+++ b/drivers/scsi/sd.c
@@ -45,6 +45,7 @@
 #include <linux/init.h>
 #include <linux/blkdev.h>
 #include <linux/blkpg.h>
+#include <linux/blk-zoned-ctrl.h>
 #include <linux/delay.h>
 #include <linux/mutex.h>
 #include <linux/string_helpers.h>
@@ -91,6 +92,7 @@ MODULE_ALIAS_BLOCKDEV_MAJOR(SCSI_DISK15_MAJOR);
 MODULE_ALIAS_SCSI_DEVICE(TYPE_DISK);
 MODULE_ALIAS_SCSI_DEVICE(TYPE_MOD);
 MODULE_ALIAS_SCSI_DEVICE(TYPE_RBC);
+MODULE_ALIAS_SCSI_DEVICE(TYPE_ZBC);
 
 #if !defined(CONFIG_DEBUG_BLOCK_EXT_DEVT)
 #define SD_MINORS	16
@@ -98,7 +100,6 @@ MODULE_ALIAS_SCSI_DEVICE(TYPE_RBC);
 #define SD_MINORS	0
 #endif
 
-static void sd_config_discard(struct scsi_disk *, unsigned int);
 static void sd_config_write_same(struct scsi_disk *);
 static int  sd_revalidate_disk(struct gendisk *);
 static void sd_unlock_native_capacity(struct gendisk *disk);
@@ -161,7 +162,7 @@ cache_type_store(struct device *dev, struct device_attribute *attr,
 	static const char temp[] = "temporary ";
 	int len;
 
-	if (sdp->type != TYPE_DISK)
+	if (sdp->type != TYPE_DISK && sdp->type != TYPE_ZBC)
 		/* no cache control on RBC devices; theoretically they
 		 * can do it, but there's probably so many exceptions
 		 * it's not worth the risk */
@@ -259,7 +260,7 @@ allow_restart_store(struct device *dev, struct device_attribute *attr,
 	if (!capable(CAP_SYS_ADMIN))
 		return -EACCES;
 
-	if (sdp->type != TYPE_DISK)
+	if (sdp->type != TYPE_DISK && sdp->type != TYPE_ZBC)
 		return -EINVAL;
 
 	sdp->allow_restart = simple_strtoul(buf, NULL, 10);
@@ -367,6 +368,7 @@ static const char *lbp_mode[] = {
 	[SD_LBP_WS16]		= "writesame_16",
 	[SD_LBP_WS10]		= "writesame_10",
 	[SD_LBP_ZERO]		= "writesame_zero",
+	[SD_ZBC_RESET_WP]	= "reset_wp",
 	[SD_LBP_DISABLE]	= "disabled",
 };
 
@@ -389,7 +391,7 @@ provisioning_mode_store(struct device *dev, struct device_attribute *attr,
 	if (!capable(CAP_SYS_ADMIN))
 		return -EACCES;
 
-	if (sdp->type != TYPE_DISK)
+	if (sdp->type != TYPE_DISK && sdp->type != TYPE_ZBC)
 		return -EINVAL;
 
 	if (!strncmp(buf, lbp_mode[SD_LBP_UNMAP], 20))
@@ -400,6 +402,8 @@ provisioning_mode_store(struct device *dev, struct device_attribute *attr,
 		sd_config_discard(sdkp, SD_LBP_WS10);
 	else if (!strncmp(buf, lbp_mode[SD_LBP_ZERO], 20))
 		sd_config_discard(sdkp, SD_LBP_ZERO);
+	else if (!strncmp(buf, lbp_mode[SD_ZBC_RESET_WP], 20))
+		sd_config_discard(sdkp, SD_ZBC_RESET_WP);
 	else if (!strncmp(buf, lbp_mode[SD_LBP_DISABLE], 20))
 		sd_config_discard(sdkp, SD_LBP_DISABLE);
 	else
@@ -456,7 +460,7 @@ max_write_same_blocks_store(struct device *dev, struct device_attribute *attr,
 	if (!capable(CAP_SYS_ADMIN))
 		return -EACCES;
 
-	if (sdp->type != TYPE_DISK)
+	if (sdp->type != TYPE_DISK && sdp->type != TYPE_ZBC)
 		return -EINVAL;
 
 	err = kstrtoul(buf, 10, &max);
@@ -650,7 +654,7 @@ static unsigned char sd_setup_protect_cmnd(struct scsi_cmnd *scmd,
 	return protect;
 }
 
-static void sd_config_discard(struct scsi_disk *sdkp, unsigned int mode)
+void sd_config_discard(struct scsi_disk *sdkp, unsigned int mode)
 {
 	struct request_queue *q = sdkp->disk->queue;
 	unsigned int logical_block_size = sdkp->device->sector_size;
@@ -689,6 +693,12 @@ static void sd_config_discard(struct scsi_disk *sdkp, unsigned int mode)
 		q->limits.discard_zeroes_data = sdkp->lbprz;
 		break;
 
+	case SD_ZBC_RESET_WP:
+		max_blocks = min_not_zero(sdkp->max_ws_blocks,
+					  (u32)SD_MAX_WS16_BLOCKS);
+		q->limits.discard_zeroes_data = 1;
+		break;
+
 	case SD_LBP_ZERO:
 		max_blocks = min_not_zero(sdkp->max_ws_blocks,
 					  (u32)SD_MAX_WS10_BLOCKS);
@@ -717,16 +727,20 @@ static int sd_setup_discard_cmnd(struct scsi_cmnd *cmd)
 	unsigned int nr_sectors = blk_rq_sectors(rq);
 	unsigned int nr_bytes = blk_rq_bytes(rq);
 	unsigned int len;
-	int ret;
+	unsigned long flags;
+	int ret = 0;
 	char *buf;
-	struct page *page;
+	struct page *page = NULL;
+	struct blk_zone *zone;
 
 	sector >>= ilog2(sdp->sector_size) - 9;
 	nr_sectors >>= ilog2(sdp->sector_size) - 9;
 
-	page = alloc_page(GFP_ATOMIC | __GFP_ZERO);
-	if (!page)
-		return BLKPREP_DEFER;
+	if (sdkp->provisioning_mode != SD_ZBC_RESET_WP) {
+		page = alloc_page(GFP_ATOMIC | __GFP_ZERO);
+		if (!page)
+			return BLKPREP_DEFER;
+	}
 
 	switch (sdkp->provisioning_mode) {
 	case SD_LBP_UNMAP:
@@ -766,6 +780,60 @@ static int sd_setup_discard_cmnd(struct scsi_cmnd *cmd)
 		len = sdkp->device->sector_size;
 		break;
 
+	case SD_ZBC_RESET_WP:
+		zone = blk_lookup_zone(rq->q, sector);
+		if (!zone) {
+			ret = BLKPREP_KILL;
+			goto out;
+		}
+		spin_lock_irqsave(&zone->lock, flags);
+		if (zone->state == BLK_ZONE_BUSY) {
+			sd_printk(KERN_INFO, sdkp,
+				  "Discarding busy zone %llu/%llu\n",
+				  zone->start, zone->len);
+			spin_unlock_irqrestore(&zone->lock, flags);
+			ret = BLKPREP_DEFER;
+			goto out;
+		}
+		if (!blk_zone_is_smr(zone)) {
+			sd_printk(KERN_INFO, sdkp,
+				  "Discarding %s zone %llu/%llu\n",
+				  blk_zone_is_cmr(zone) ? "CMR" : "unknown",
+				  zone->start, zone->len);
+			spin_unlock_irqrestore(&zone->lock, flags);
+			ret = BLKPREP_DONE;
+			goto out;
+		}
+		if (blk_zone_is_empty(zone)) {
+			spin_unlock_irqrestore(&zone->lock, flags);
+			ret = BLKPREP_DONE;
+			goto out;
+		}
+		if (zone->start != sector ||
+		    zone->len < nr_sectors) {
+			sd_printk(KERN_INFO, sdkp,
+				  "Misaligned RESET WP, start %llu/%zu "
+				  "len %llu/%u\n",
+				  zone->start, sector, zone->len, nr_sectors);
+			spin_unlock_irqrestore(&zone->lock, flags);
+			ret = BLKPREP_KILL;
+			goto out;
+		}
+		/*
+		 * Opportunistic setting, needs to be fixed up
+		 * if RESET WRITE POINTER fails.
+		 */
+		zone->wp = zone->start;
+		spin_unlock_irqrestore(&zone->lock, flags);
+		cmd->cmd_len = 16;
+		cmd->cmnd[0] = ZBC_OUT;
+		cmd->cmnd[1] = ZO_RESET_WRITE_POINTER;
+		put_unaligned_be64(sector, &cmd->cmnd[2]);
+		/* RESET WRITE POINTER doesn't have a payload */
+		len = 0;
+		cmd->sc_data_direction = DMA_NONE;
+		break;
+
 	default:
 		ret = BLKPREP_KILL;
 		goto out;
@@ -785,12 +853,14 @@ static int sd_setup_discard_cmnd(struct scsi_cmnd *cmd)
 	 * discarded on disk. This allows us to report completion on the full
 	 * amount of blocks described by the request.
 	 */
-	blk_add_request_payload(rq, page, len);
-	ret = scsi_init_io(cmd);
+	if (len) {
+		blk_add_request_payload(rq, page, len);
+		ret = scsi_init_io(cmd);
+	}
 	rq->__data_len = nr_bytes;
 
 out:
-	if (ret != BLKPREP_OK)
+	if (page && ret != BLKPREP_OK)
 		__free_page(page);
 	return ret;
 }
@@ -1009,6 +1079,13 @@ static int sd_setup_read_write_cmnd(struct scsi_cmnd *SCpnt)
 			this_count = this_count >> 3;
 		}
 	}
+#ifdef CONFIG_SCSI_ZBC
+	if (sdp->zoned) {
+		ret = sd_zbc_lookup_zone(sdkp, rq, block, this_count);
+		if (ret != BLKPREP_OK)
+			goto out;
+	}
+#endif
 	if (rq_data_dir(rq) == WRITE) {
 		SCpnt->cmnd[0] = WRITE_6;
 
@@ -1157,7 +1234,8 @@ static void sd_uninit_command(struct scsi_cmnd *SCpnt)
 {
 	struct request *rq = SCpnt->request;
 
-	if (rq->cmd_flags & REQ_DISCARD)
+	if (rq->cmd_flags & REQ_DISCARD &&
+	    rq->completion_data)
 		__free_page(rq->completion_data);
 
 	if (SCpnt->cmnd != rq->cmd) {
@@ -1351,6 +1429,21 @@ static int sd_ioctl(struct block_device *bdev, fmode_t mode,
 		case SCSI_IOCTL_GET_BUS_NUMBER:
 			error = scsi_ioctl(sdp, cmd, p);
 			break;
+		case SCSI_IOCTL_INQUIRY:
+			error = _inquiry_ioctl(disk, p);
+			break;
+		case SCSI_IOCTL_REPORT_ZONES:
+			error = _report_zones_ioctl(disk, p);
+			break;
+		case SCSI_IOCTL_RESET_WP:
+			error = _reset_wp_ioctl(disk, arg);
+			break;
+		case SCSI_IOCTL_OPEN_ZONE:
+			error = -EFAULT;
+			break;
+		case SCSI_IOCTL_CLOSE_ZONE:
+			error = -EFAULT;
+			break;
 		default:
 			error = scsi_cmd_blk_ioctl(bdev, mode, cmd, p);
 			if (error != -ENOTTY)
@@ -1687,12 +1780,17 @@ static int sd_done(struct scsi_cmnd *SCpnt)
 	int sense_deferred = 0;
 	unsigned char op = SCpnt->cmnd[0];
 	unsigned char unmap = SCpnt->cmnd[1] & 8;
+	unsigned char sa = SCpnt->cmnd[1] & 0xf;
 
 	if (req->cmd_flags & REQ_DISCARD || req->cmd_flags & REQ_WRITE_SAME) {
 		if (!result) {
 			good_bytes = blk_rq_bytes(req);
 			scsi_set_resid(SCpnt, 0);
 		} else {
+			if (op == ZBC_OUT)
+				sd_zbc_update_zones(sdkp,
+						    blk_rq_pos(req),
+						    512, true);
 			good_bytes = 0;
 			scsi_set_resid(SCpnt, blk_rq_bytes(req));
 		}
@@ -1738,6 +1836,10 @@ static int sd_done(struct scsi_cmnd *SCpnt)
 			case UNMAP:
 				sd_config_discard(sdkp, SD_LBP_DISABLE);
 				break;
+			case ZBC_OUT:
+				if (sa == ZO_RESET_WRITE_POINTER)
+					sd_config_discard(sdkp, SD_LBP_DISABLE);
+				break;
 			case WRITE_SAME_16:
 			case WRITE_SAME:
 				if (unmap)
@@ -1752,6 +1854,35 @@ static int sd_done(struct scsi_cmnd *SCpnt)
 				}
 			}
 		}
+		if (sshdr.asc == 0x21) {
+			/*
+			 * ZBC: read beyond the write pointer position.
+			 * Clear out error and return the buffer as-is.
+			 */
+			if (sshdr.ascq == 0x06) {
+				good_bytes = blk_rq_bytes(req);
+				scsi_set_resid(SCpnt, 0);
+			}
+#ifdef CONFIG_SCSI_ZBC
+			/*
+			 * ZBC: Unaligned write command.
+			 * Write did not start a write pointer position.
+			 */
+			if (sshdr.ascq == 0x04) {
+				u64 wp_pos;
+				if (scsi_get_sense_info_fld(SCpnt->sense_buffer,
+							    SCSI_SENSE_BUFFERSIZE,
+							    &wp_pos)) {
+					sd_zbc_update_wp(sdkp, blk_rq_pos(req),
+							 wp_pos);
+				} else {
+					sd_zbc_update_zones(sdkp,
+							    blk_rq_pos(req),
+							    512, true);
+				}
+			}
+#endif
+		}
 		break;
 	default:
 		break;
@@ -2535,7 +2666,7 @@ static void sd_read_app_tag_own(struct scsi_disk *sdkp, unsigned char *buffer)
 	struct scsi_mode_data data;
 	struct scsi_sense_hdr sshdr;
 
-	if (sdp->type != TYPE_DISK)
+	if (sdp->type != TYPE_DISK && sdp->type != TYPE_ZBC)
 		return;
 
 	if (sdkp->protection_type == 0)
@@ -2664,6 +2795,7 @@ static void sd_read_block_characteristics(struct scsi_disk *sdkp)
 		queue_flag_clear_unlocked(QUEUE_FLAG_ADD_RANDOM, sdkp->disk->queue);
 	}
 
+	sdkp->device->zoned = (buffer[8] & 0x10) ? 1 : 0;
  out:
 	kfree(buffer);
 }
@@ -2694,6 +2826,28 @@ static void sd_read_block_provisioning(struct scsi_disk *sdkp)
 	kfree(buffer);
 }
 
+/**
+ * sd_read_zoned_block_characteristics - Query zoned block device
+ * characteristics VPD page
+ * @disk: disk to query
+ */
+static void sd_read_zoned_block_characteristics(struct scsi_disk *sdkp)
+{
+	unsigned char *buffer;
+	const int vpd_len = 64;
+
+	buffer = kmalloc(vpd_len, GFP_KERNEL);
+
+	if (!buffer || scsi_get_vpd_page(sdkp->device, 0xb6, buffer, vpd_len))
+		goto out;
+
+	sdkp->unmap_alignment = sdkp->disk->queue->zone_len;
+	sd_config_discard(sdkp, SD_ZBC_RESET_WP);
+
+ out:
+	kfree(buffer);
+}
+
 static void sd_read_write_same(struct scsi_disk *sdkp, unsigned char *buffer)
 {
 	struct scsi_device *sdev = sdkp->device;
@@ -2784,6 +2938,8 @@ static int sd_revalidate_disk(struct gendisk *disk)
 			sd_read_block_provisioning(sdkp);
 			sd_read_block_limits(sdkp);
 			sd_read_block_characteristics(sdkp);
+			if (sdp->zoned)
+				sd_read_zoned_block_characteristics(sdkp);
 		}
 
 		sd_read_write_protect_flag(sdkp, buffer);
@@ -2794,6 +2950,11 @@ static int sd_revalidate_disk(struct gendisk *disk)
 
 	sdkp->first_scan = 0;
 
+	if (sdp->zoned) {
+		sd_zbc_init_zones(sdkp, buffer, SD_BUF_SIZE);
+		sd_config_discard(sdkp, SD_ZBC_RESET_WP);
+	}
+
 	/*
 	 * We now have all cache related info, determine how we deal
 	 * with flush requests.
@@ -2802,7 +2963,6 @@ static int sd_revalidate_disk(struct gendisk *disk)
 
 	max_xfer = sdkp->max_xfer_blocks;
 	max_xfer <<= ilog2(sdp->sector_size) - 9;
-
 	max_xfer = min_not_zero(queue_max_hw_sectors(sdkp->disk->queue),
 				max_xfer);
 	blk_queue_max_hw_sectors(sdkp->disk->queue, max_xfer);
@@ -2961,13 +3121,24 @@ static int sd_probe(struct device *dev)
 	struct scsi_device *sdp = to_scsi_device(dev);
 	struct scsi_disk *sdkp;
 	struct gendisk *gd;
+#ifdef CONFIG_SCSI_ZBC
+	char zone_work_q_name[32];
+#endif
 	int index;
 	int error;
 
 	scsi_autopm_get_device(sdp);
 	error = -ENODEV;
-	if (sdp->type != TYPE_DISK && sdp->type != TYPE_MOD && sdp->type != TYPE_RBC)
+	if (sdp->type != TYPE_DISK &&
+	    sdp->type != TYPE_ZBC &&
+	    sdp->type != TYPE_MOD &&
+	    sdp->type != TYPE_RBC)
+		goto out;
+
+#ifndef CONFIG_SCSI_ZBC
+	if (sdp->type == TYPE_ZBC)
 		goto out;
+#endif
 
 	SCSI_LOG_HLQUEUE(3, sdev_printk(KERN_INFO, sdp,
 					"sd_probe\n"));
@@ -3008,6 +3179,21 @@ static int sd_probe(struct device *dev)
 	atomic_set(&sdkp->openers, 0);
 	atomic_set(&sdkp->device->ioerr_cnt, 0);
 
+#ifdef CONFIG_SCSI_ZBC
+	sprintf(zone_work_q_name, "zbc_wq_%s", gd->disk_name);
+	sdkp->zone_work_q = create_singlethread_workqueue(zone_work_q_name);
+	if (!sdkp->zone_work_q) {
+		sdev_printk(KERN_WARNING, sdp,
+			    "create zoned disk workqueue failed\n");
+		goto out_free_index;
+	}
+	INIT_WORK(&sdkp->zone_work, sd_zbc_refresh_zone_work);
+	sdkp->zone_buf = NULL;
+	sdkp->zone_wp = -1;
+	sdkp->zone_lba = -1;
+	spin_lock_init(&sdkp->zone_lock);
+#endif
+
 	if (!sdp->request_queue->rq_timeout) {
 		if (sdp->type != TYPE_MOD)
 			blk_queue_rq_timeout(sdp->request_queue, SD_TIMEOUT);
@@ -3022,7 +3208,7 @@ static int sd_probe(struct device *dev)
 	dev_set_name(&sdkp->dev, "%s", dev_name(dev));
 
 	if (device_add(&sdkp->dev))
-		goto out_free_index;
+		goto out_free_wq;
 
 	get_device(dev);
 	dev_set_drvdata(dev, sdkp);
@@ -3032,6 +3218,10 @@ static int sd_probe(struct device *dev)
 
 	return 0;
 
+ out_free_wq:
+#ifdef CONFIG_SCSI_ZBC
+	destroy_workqueue(sdkp->zone_work_q);
+#endif
  out_free_index:
 	spin_lock(&sd_index_lock);
 	ida_remove(&sd_index_ida, index);
@@ -3071,6 +3261,9 @@ static int sd_remove(struct device *dev)
 	del_gendisk(sdkp->disk);
 	sd_shutdown(dev);
 
+#ifdef CONFIG_SCSI_ZBC
+	destroy_workqueue(sdkp->zone_work_q);
+#endif
 	blk_register_region(devt, SD_MINORS, NULL,
 			    sd_default_probe, NULL, NULL);
 
@@ -3100,6 +3293,8 @@ static void scsi_disk_release(struct device *dev)
 	ida_remove(&sd_index_ida, sdkp->index);
 	spin_unlock(&sd_index_lock);
 
+	sd_zbc_remove_zones(sdkp);
+
 	disk->private_data = NULL;
 	put_disk(disk);
 	put_device(&sdkp->device->sdev_gendev);
@@ -3167,6 +3362,8 @@ static void sd_shutdown(struct device *dev)
 		sd_start_stop_device(sdkp, 0);
 	}
 
+	sd_zbc_reset_zones(sdkp);
+
 exit:
 	scsi_disk_put(sdkp);
 }
diff --git a/drivers/scsi/sd.h b/drivers/scsi/sd.h
index 63ba5ca..43fb5f6 100644
--- a/drivers/scsi/sd.h
+++ b/drivers/scsi/sd.h
@@ -56,6 +56,7 @@ enum {
 	SD_LBP_WS16,		/* Use WRITE SAME(16) with UNMAP bit */
 	SD_LBP_WS10,		/* Use WRITE SAME(10) with UNMAP bit */
 	SD_LBP_ZERO,		/* Use WRITE SAME(10) with zero payload */
+	SD_ZBC_RESET_WP,	/* Use RESET WRITE POINTER */
 	SD_LBP_DISABLE,		/* Discard disabled due to failed cmd */
 };
 
@@ -64,6 +65,18 @@ struct scsi_disk {
 	struct scsi_device *device;
 	struct device	dev;
 	struct gendisk	*disk;
+#ifdef CONFIG_SCSI_ZBC
+	struct workqueue_struct *zone_work_q;
+	struct work_struct zone_work;
+	spinlock_t	zone_lock;
+	sector_t	zone_lba;
+	sector_t	zone_wp;
+	char		*zone_buf;
+	int		zone_buflen;
+	bool		zone_update;
+	u32		zone_num;
+	u64		max_lba;
+#endif
 	atomic_t	openers;
 	sector_t	capacity;	/* size in 512-byte sectors */
 	u32		max_xfer_blocks;
@@ -258,4 +271,38 @@ static inline void sd_dif_complete(struct scsi_cmnd *cmd, unsigned int a)
 
 #endif /* CONFIG_BLK_DEV_INTEGRITY */
 
+#ifdef CONFIG_SCSI_ZBC
+
+extern int sd_zbc_init_zones(struct scsi_disk *, unsigned char *, int);
+extern void sd_zbc_remove_zones(struct scsi_disk *);
+extern void sd_zbc_reset_zones(struct scsi_disk *);
+extern int sd_zbc_lookup_zone(struct scsi_disk *, struct request *,
+			      sector_t, unsigned int);
+extern void sd_zbc_update_zones(struct scsi_disk *, sector_t, int, bool);
+extern void sd_zbc_refresh_zone_work(struct work_struct *);
+extern void sd_zbc_update_wp(struct scsi_disk *, sector_t, sector_t);
+
+#else /* CONFIG_SCSI_ZBC */
+
+static inline int sd_zbc_init_zones(struct scsi_disk *sdkp,
+				    unsigned char *buf, int buf_len)
+{
+	return 0;
+}
+
+static inline void sd_zbc_remove_zones(struct scsi_disk *sdkp)
+{
+}
+
+static struct blk_zone *sd_zbc_lookup_zone(struct scsi_disk *sdkp,
+					   struct request *rq, sector_t sector,
+					   unsigned int num_sectors)
+{
+	return NULL;
+}
+
+#endif /* CONFIG_SCSI_ZBC */
+
+extern void sd_config_discard(struct scsi_disk *, unsigned int);
+
 #endif /* _SCSI_DISK_H */
diff --git a/drivers/scsi/sd_zbc.c b/drivers/scsi/sd_zbc.c
new file mode 100644
index 0000000..3b988dc
--- /dev/null
+++ b/drivers/scsi/sd_zbc.c
@@ -0,0 +1,586 @@
+/*
+ * sd_zbc.c - SCSI Zoned Block commands
+ *
+ * Copyright (C) 2014 SUSE Linux Products GmbH
+ * Written by: Hannes Reinecke <hare@suse.de>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License version
+ * 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; see the file COPYING.  If not, write to
+ * the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139,
+ * USA.
+ *
+ */
+
+#include <linux/blkdev.h>
+#include <linux/rbtree.h>
+
+#include <asm/unaligned.h>
+
+#include <scsi/scsi.h>
+#include <scsi/scsi_cmnd.h>
+#include <scsi/scsi_dbg.h>
+#include <scsi/scsi_device.h>
+#include <scsi/scsi_driver.h>
+#include <scsi/scsi_host.h>
+#include <scsi/scsi_eh.h>
+
+#include "sd.h"
+#include "scsi_priv.h"
+
+enum zbc_zone_cond {
+	ZBC_ZONE_COND_NO_WP,
+	ZBC_ZONE_COND_EMPTY,
+	ZBC_ZONE_COND_IMPLICIT_OPEN,
+	ZBC_ZONE_COND_EXPLICIT_OPEN,
+	ZBC_ZONE_COND_CLOSED,
+	ZBC_ZONE_COND_READONLY = 0xd,
+	ZBC_ZONE_COND_FULL,
+	ZBC_ZONE_COND_OFFLINE,
+};
+
+enum zbc_zone_same {
+	ZBC_ZONE_SAME_NONE                  = 0,
+	ZBC_ZONE_SAME_ALL                   = 1,
+	ZBC_ZONE_SAME_LAST_ZONE_DIFFERS     = 2,
+	ZBC_ZONE_SAME_ALL_LEN_TYPES_DIFFER  = 3,
+};
+
+#define SD_ZBC_BUF_SIZE 65536
+#define SD_ZBC_QUEUE_DELAY 5
+
+static int sd_zbc_chunk_limits(struct request_queue *, sector_t);
+
+static int
+zbc_report_zone(struct scsi_disk *sdkp, sector_t start_lba,
+		unsigned char *buffer, int bufflen )
+{
+	struct scsi_device *sdp = sdkp->device;
+	const int timeout = sdp->request_queue->rq_timeout
+		* SD_FLUSH_TIMEOUT_MULTIPLIER;
+	struct scsi_sense_hdr sshdr;
+	unsigned char cmd[16];
+	int result;
+
+	if (!scsi_device_online(sdp)) {
+		sd_printk(KERN_INFO, sdkp, "device not online\n");
+		return -ENODEV;
+	}
+
+	sd_printk(KERN_INFO, sdkp, "REPORT ZONES lba %zu len %d\n",
+		  start_lba, bufflen);
+
+	memset(cmd, 0, 16);
+	cmd[0] = ZBC_IN;
+	cmd[1] = ZI_REPORT_ZONES;
+	put_unaligned_be64(start_lba, &cmd[2]);
+	put_unaligned_be32(bufflen, &cmd[10]);
+	memset(buffer, 0, bufflen);
+
+	result = scsi_execute_req(sdp, cmd, DMA_FROM_DEVICE,
+				  buffer, bufflen, &sshdr,
+				  timeout, SD_MAX_RETRIES, NULL);
+
+	if (result) {
+		sd_printk(KERN_NOTICE, sdkp,
+			  "REPORT ZONES lba %zu failed with %d/%d\n",
+			  start_lba, host_byte(result), driver_byte(result));
+		return -EINVAL;
+	}
+	return 0;
+}
+
+struct blk_zone *zbc_desc_to_zone(struct scsi_disk *sdkp, unsigned char *rec,
+				  int bflags)
+{
+	struct blk_zone *zone;
+	enum zbc_zone_cond zone_cond;
+	u64 wp = (u64)-1;
+
+	zone = kzalloc(sizeof(struct blk_zone), GFP_KERNEL);
+	if (!zone)
+		return NULL;
+
+	spin_lock_init(&zone->lock);
+	zone->type = rec[0] & 0xf;
+	zone_cond = (rec[1] >> 4) & 0xf;
+	zone->len = get_unaligned_be64(&rec[8]);
+	zone->start = get_unaligned_be64(&rec[16]);
+
+	if (blk_zone_is_smr(zone)) {
+		wp = get_unaligned_be64(&rec[24]);
+		if (zone_cond == ZBC_ZONE_COND_READONLY) {
+			zone->state = BLK_ZONE_READONLY;
+		} else if (zone_cond == ZBC_ZONE_COND_OFFLINE) {
+			zone->state = BLK_ZONE_OFFLINE;
+		} else {
+			zone->state = BLK_ZONE_OPEN;
+		}
+	} else
+		zone->state = BLK_ZONE_NO_WP;
+
+	zone->wp = zone->shadow_wp = wp;
+	/*
+	 * Fixup block zone state
+	 */
+	if (zone_cond == ZBC_ZONE_COND_EMPTY &&
+	    zone->wp != zone->start) {
+		sd_printk(KERN_INFO, sdkp,
+			  "zone %llu state EMPTY wp %llu: adjust wp\n",
+			  zone->start, zone->wp);
+		zone->wp = zone->start;
+	}
+	if (zone_cond == ZBC_ZONE_COND_FULL &&
+	    zone->wp != zone->start + zone->len) {
+		sd_printk(KERN_INFO, sdkp,
+			  "zone %llu state FULL wp %llu: adjust wp\n",
+			  zone->start, zone->wp);
+		zone->wp = zone->start + zone->len;
+	}
+
+	return zone;
+}
+
+sector_t zbc_parse_zones(struct scsi_disk *sdkp, unsigned char *buf,
+			 unsigned int *buf_len, sector_t start_lba, int bflags)
+{
+	struct request_queue *q = sdkp->disk->queue;
+	unsigned char *rec = buf;
+	int rec_no = 0, start_rec = 0;
+	unsigned int list_length, zone_len = q->zone_len;
+	sector_t last_lba = 0;
+	u8 same;
+
+	/* Parse REPORT ZONES header */
+	list_length = get_unaligned_be32(&buf[0]);
+	same = buf[4] & 0xf;
+	if (same > 0 && zone_len)
+		rec_no = start_rec = start_lba / zone_len;
+	rec = buf + 64;
+	list_length += 64;
+
+	if (list_length < *buf_len)
+		*buf_len = list_length;
+
+	while (rec < buf + *buf_len) {
+		struct blk_zone *this, *old;
+		unsigned long flags;
+
+		this = zbc_desc_to_zone(sdkp, rec, bflags);
+		if (!this)
+			break;
+
+		if (last_lba <= this->start)
+			last_lba = this->start + this->len;
+		old = blk_insert_zone(q, this);
+		if (old) {
+			spin_lock_irqsave(&old->lock, flags);
+			if (old->state == BLK_ZONE_BUSY ||
+			    old->state == BLK_ZONE_UNKNOWN) {
+				old->wp = this->wp;
+				old->shadow_wp = this->shadow_wp;
+				old->state = this->state;
+			}
+			spin_unlock_irqrestore(&old->lock, flags);
+			kfree(this);
+		} else if (blk_zone_is_smr(this)) {
+			if (!zone_len || this->len > zone_len)
+				zone_len = this->len;
+		}
+		rec += 64;
+		rec_no++;
+	}
+	if (!q->zone_len && zone_len)
+		q->zone_len = zone_len;
+
+	if (start_lba == 0) {
+		sd_printk(KERN_INFO, sdkp,
+			  "Setting queue limits same %d len %zu\n",
+			  same, q->zone_len);
+		if (   (ZBC_ZONE_SAME_ALL == same)
+		    || (ZBC_ZONE_SAME_ALL_LEN_TYPES_DIFFER == same) ) {
+			/* Zone sizes are identical */
+			sdkp->unmap_granularity = q->zone_len;
+			sdkp->max_ws_blocks = q->zone_len;
+			blk_queue_chunk_sectors(sdkp->disk->queue, q->zone_len);
+		} else {
+			/* One or more zones differ byte size */
+			blk_queue_chunk_limits(sdkp->disk->queue,
+					       sd_zbc_chunk_limits);
+		}
+		sd_config_discard(sdkp, SD_ZBC_RESET_WP);
+	}
+	sd_printk(KERN_INFO, sdkp,
+		  "Inserted %d zones (%d - %d), next lba %zu len %d\n",
+		  rec_no, start_rec, rec_no, last_lba, list_length);
+	if (*buf_len < list_length) {
+		*buf_len = list_length;
+		return last_lba;
+	}
+	return 0;
+}
+
+static void sd_zbc_refresh_wp(struct scsi_disk *sdkp, sector_t wp)
+{
+	struct request_queue *q = sdkp->disk->queue;
+	struct blk_zone *zone;
+	unsigned long flags;
+
+	if (sdkp->zone_buf) {
+		/* zone update in progress */
+		sd_printk(KERN_INFO, sdkp,
+			  "zone update in progress\n");
+		return;
+	}
+	zone = blk_lookup_zone(q, wp);
+	if (!zone)
+		return;
+
+	spin_lock_irqsave(&zone->lock, flags);
+	if (blk_zone_is_cmr(zone))
+		goto out;
+	if (zone->state == BLK_ZONE_BUSY) {
+		sd_printk(KERN_INFO, sdkp,
+			  "zone busy, not updating wp");
+		goto out;
+	}
+
+	zone->wp = zone->shadow_wp = wp;
+	zone->state = BLK_ZONE_OPEN;
+out:
+	spin_unlock_irqrestore(&zone->lock, flags);
+}
+
+void sd_zbc_refresh_zone_work(struct work_struct *work)
+{
+	struct scsi_disk *sdkp =
+		container_of(work, struct scsi_disk, zone_work);
+	struct request_queue *q = sdkp->disk->queue;
+	unsigned long flags;
+	unsigned int zone_buflen;
+	void *zone_buf;
+	int bflags, ret;
+	sector_t last_lba, zone_lba, zone_wp;
+
+	spin_lock_irqsave(&sdkp->zone_lock, flags);
+	if (sdkp->zone_wp != -1) {
+		zone_wp = sdkp->zone_wp;
+		sdkp->zone_wp = (sector_t)-1;
+		sd_zbc_refresh_wp(sdkp, zone_wp);
+	}
+	if (!sdkp->zone_buf) {
+		sd_printk(KERN_INFO, sdkp,
+			  "zone update sector %zu cancelled\n",
+			  sdkp->zone_lba);
+		spin_unlock_irqrestore(&sdkp->zone_lock, flags);
+		goto done_start_queue;
+	}
+	zone_lba = sdkp->zone_lba;
+	zone_buf = sdkp->zone_buf;
+	zone_buflen = sdkp->zone_buflen;
+	spin_unlock_irqrestore(&sdkp->zone_lock, flags);
+
+	bflags = scsi_get_device_flags_keyed(sdkp->device,
+					     &sdkp->device->inquiry[8],
+					     &sdkp->device->inquiry[16],
+					     SCSI_DEVINFO_GLOBAL);
+
+	ret = zbc_report_zone(sdkp, zone_lba,
+			      zone_buf, zone_buflen);
+	if (ret)
+		goto done_free;
+
+	last_lba = zbc_parse_zones(sdkp, sdkp->zone_buf, &zone_buflen,
+				   zone_lba, bflags);
+	if (last_lba && !sdkp->zone_update) {
+		spin_lock_irqsave(&sdkp->zone_lock, flags);
+		sdkp->zone_lba = last_lba;
+		spin_unlock_irqrestore(&sdkp->zone_lock, flags);
+		queue_work(sdkp->zone_work_q, &sdkp->zone_work);
+		/* Kick request queue to be on the safe side */
+		goto done_start_queue;
+	}
+done_free:
+	spin_lock_irqsave(&sdkp->zone_lock, flags);
+	kfree(sdkp->zone_buf);
+	sdkp->zone_buf = NULL;
+	spin_unlock_irqrestore(&sdkp->zone_lock, flags);
+done_start_queue:
+	spin_lock_irqsave(q->queue_lock, flags);
+	blk_start_queue(q);
+	spin_unlock_irqrestore(q->queue_lock, flags);
+}
+
+void sd_zbc_update_zones(struct scsi_disk *sdkp, sector_t lba, int bufsize,
+			 bool update)
+{
+	struct request_queue *q = sdkp->disk->queue;
+	void *zone_buf;
+	struct blk_zone *zone;
+	unsigned long flags;
+
+retry:
+	zone_buf = kzalloc(bufsize, GFP_KERNEL);
+	if (!zone_buf) {
+		if (bufsize > 512) {
+			sd_printk(KERN_INFO, sdkp,
+				  "retry with buffer size %d\n", bufsize);
+			bufsize = bufsize >> 1;
+			goto retry;
+		}
+		sd_printk(KERN_INFO, sdkp,
+			  "failed to allocate %d bytes\n", bufsize);
+		return;
+	}
+	spin_lock_irqsave(&sdkp->zone_lock, flags);
+	if (sdkp->zone_buf) {
+		spin_unlock_irqrestore(&sdkp->zone_lock, flags);
+		kfree(zone_buf);
+		/* zone update in progress */
+		sd_printk(KERN_INFO, sdkp,
+			  "zone update in progress\n");
+		return;
+	}
+	sdkp->zone_buf = zone_buf;
+	sdkp->zone_lba = lba;
+	sdkp->zone_buflen = bufsize;
+	sdkp->zone_update = update;
+	spin_unlock_irqrestore(&sdkp->zone_lock, flags);
+
+	if (!update) {
+		struct blk_zone *next;
+
+		rbtree_postorder_for_each_entry_safe(zone, next,
+						     &q->zones, node) {
+			unsigned long flags;
+
+			if (zone->start + zone->len <= lba)
+				continue;
+
+			spin_lock_irqsave(&zone->lock, flags);
+			if (blk_zone_is_smr(zone))
+				zone->state = BLK_ZONE_BUSY;
+			spin_unlock_irqrestore(&zone->lock, flags);
+		}
+	}
+
+	if (!queue_work(sdkp->zone_work_q, &sdkp->zone_work)) {
+		sd_printk(KERN_INFO, sdkp,
+			  "zone update already queued?\n");
+	}
+}
+
+void sd_zbc_update_wp(struct scsi_disk *sdkp, sector_t lba, sector_t wp)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&sdkp->zone_lock, flags);
+	if (sdkp->zone_wp != -1) {
+		sd_printk(KERN_INFO, sdkp,
+			  "WP update in progress, wp %zu / %zu\n",
+			  wp, sdkp->zone_wp);
+		spin_unlock_irqrestore(&sdkp->zone_lock, flags);
+		return;
+	}
+	sdkp->zone_wp = wp;
+	spin_unlock_irqrestore(&sdkp->zone_lock, flags);
+	if (!queue_work(sdkp->zone_work_q, &sdkp->zone_work))
+		sd_printk(KERN_INFO, sdkp,
+			  "zone update already queued for wp update\n");
+}
+
+int sd_zbc_lookup_zone(struct scsi_disk *sdkp, struct request *rq,
+		       sector_t sector, unsigned int num_sectors)
+{
+	struct request_queue *q = sdkp->disk->queue;
+	struct blk_zone *zone = NULL;
+	int ret = BLKPREP_OK;
+	unsigned long flags;
+
+	/* Simple last-hit cache to save rbtree lookups */
+	if (q->zone_cache && q->zone_cache->start < sector &&
+	    q->zone_cache->start + q->zone_cache->len > sector) {
+		zone = q->zone_cache;
+#if 0
+		if (blk_zone_is_smr(zone))
+			sd_printk(KERN_INFO, sdkp,
+				  "SMR zone %x %llu/%llu %lld (cached)\n",
+				  zone->state, zone->start,
+				  zone->len, zone->wp);
+#endif
+	} else {
+		zone = blk_lookup_zone(q, sector);
+#if 0
+		if (zone && blk_zone_is_smr(zone))
+			sd_printk(KERN_INFO, sdkp,
+				  "SMR zone %x %llu/%llu %lld\n",
+				  zone->state, zone->start,
+				  zone->len, zone->wp);
+#endif
+		q->zone_cache = zone;
+	}
+	/* Might happen during zone initialization */
+	if (!zone) {
+		if (printk_ratelimit())
+			sd_printk(KERN_INFO, sdkp,
+				  "zone for sector %zu not found, %s\n",
+				  sector, sdkp->device->type == TYPE_ZBC ?
+				  "deferring" : "skipping");
+		if (sdkp->device->type != TYPE_ZBC)
+			return BLKPREP_OK;
+		blk_delay_queue(q, 5);
+		return BLKPREP_DEFER;
+	}
+	spin_lock_irqsave(&zone->lock, flags);
+	if (zone->state == BLK_ZONE_UNKNOWN ||
+	    zone->state == BLK_ZONE_BUSY) {
+		if (printk_ratelimit())
+			sd_printk(KERN_INFO, sdkp,
+				  "zone %llu state %x, deferring\n",
+				  zone->start, zone->state);
+		q->zone_cache = NULL;
+		blk_delay_queue(q, 5);
+		ret = BLKPREP_DEFER;
+	} else if (zone->type == BLK_ZONE_TYPE_SEQWRITE_REQ) {
+		if (rq_data_dir(rq) == WRITE) {
+			if (rq->cmd_flags & REQ_WPUPDATE) {
+				if (zone->wp < sector &&
+				    zone->shadow_wp > zone->wp) {
+					sd_printk(KERN_ERR, sdkp,
+						  "Non-sequential write "
+						  "%llu/%zu/%llu, requeue\n",
+						  zone->wp, sector,
+						  zone->shadow_wp);
+					rq->cmd_flags &= ~REQ_WPUPDATE;
+					ret = BLKPREP_REQUEUE;
+					goto out;
+				}
+			}
+
+			if (blk_zone_is_full(zone)) {
+				sd_printk(KERN_ERR, sdkp,
+					  "Write to full zone %zu/%llu\n",
+					  sector, zone->wp);
+				ret = BLKPREP_KILL;
+				goto out;
+			}
+			if (zone->wp != sector) {
+				sd_printk(KERN_ERR, sdkp,
+					  "Misaligned write %zu/%llu\n",
+					  sector, zone->wp);
+				ret = BLKPREP_KILL;
+				goto out;
+			}
+			zone->wp += num_sectors;
+		} else if (zone->wp <= sector) {
+			sd_printk(KERN_INFO, sdkp,
+				    "Read beyond wp %zu/%llu\n",
+				    sector, zone->wp);
+			ret = BLKPREP_DONE;
+		}
+	}
+out:
+	spin_unlock_irqrestore(&zone->lock, flags);
+
+	return ret;
+}
+
+static int sd_zbc_chunk_limits(struct request_queue *q, sector_t sector)
+{
+	struct blk_zone *zone = NULL;
+
+	/* Simple last-hit cache to save rbtree lookups */
+	if (q->zone_cache && q->zone_cache->start < sector &&
+	    q->zone_cache->start + q->zone_cache->len > sector)
+		zone = q->zone_cache;
+	else {
+		zone = blk_lookup_zone(q, sector);
+		q->zone_cache = zone;
+	}
+
+	if (!zone)
+		return q->limits.max_sectors;
+
+	return zone->start + zone->len - sector;
+}
+
+void sd_zbc_reset_zones(struct scsi_disk *sdkp)
+{
+	struct request_queue *q = sdkp->disk->queue;
+	struct rb_root *root = &q->zones;
+	struct blk_zone *zone, *next;
+	unsigned long flags;
+
+	rbtree_postorder_for_each_entry_safe(zone, next, root, node) {
+		spin_lock_irqsave(&zone->lock, flags);
+		zone->wp = zone->shadow_wp = -1;
+		zone->state = BLK_ZONE_UNKNOWN;
+		spin_unlock_irqrestore(&zone->lock, flags);
+	}
+}
+
+int sd_zbc_init_zones(struct scsi_disk *sdkp, unsigned char *buf, int buf_len)
+{
+	int ret;
+	int bflags;
+	unsigned long flags;
+
+	cancel_work_sync(&sdkp->zone_work);
+	spin_lock_irqsave(&sdkp->zone_lock, flags);
+	if (sdkp->zone_buf) {
+		kfree(sdkp->zone_buf);
+		sdkp->zone_buf = NULL;
+	}
+	sdkp->zone_wp = -1;
+	spin_unlock_irqrestore(&sdkp->zone_lock, flags);
+	sd_zbc_reset_zones(sdkp);
+
+	bflags = scsi_get_device_flags_keyed(sdkp->device,
+					     &sdkp->device->inquiry[8],
+					     &sdkp->device->inquiry[16],
+					     SCSI_DEVINFO_GLOBAL);
+
+	ret = zbc_report_zone(sdkp, 0, buf, buf_len);
+	if (!ret) {
+		sector_t last_lba;
+		unsigned int zbc_buf_len = buf_len;
+
+		last_lba = zbc_parse_zones(sdkp, buf, &zbc_buf_len, 0, bflags);
+		if (last_lba) {
+			/* ZAC can only handle 512-byte transfers */
+			if (zbc_buf_len & 0x1ff)
+				zbc_buf_len = (zbc_buf_len / 2) & ~0x1ff;
+			sd_zbc_update_zones(sdkp, last_lba,
+					    zbc_buf_len, false);
+		}
+	}
+
+	blk_queue_io_min(sdkp->disk->queue, 4);
+	return 0;
+}
+
+void sd_zbc_remove_zones(struct scsi_disk *sdkp)
+{
+	struct request_queue *q = sdkp->disk->queue;
+	unsigned long flags;
+
+	cancel_work_sync(&sdkp->zone_work);
+	spin_lock_irqsave(&sdkp->zone_lock, flags);
+	if (sdkp->zone_buf) {
+		kfree(sdkp->zone_buf);
+		sdkp->zone_buf = NULL;
+	}
+	sdkp->zone_wp = -1;
+	spin_unlock_irqrestore(&sdkp->zone_lock, flags);
+	q->zone_cache = NULL;
+	sd_printk(KERN_INFO, sdkp,
+		  "Drop zone information\n");
+}

